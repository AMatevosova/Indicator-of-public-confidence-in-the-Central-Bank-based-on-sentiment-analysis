{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-27T15:25:24.247332Z",
     "iopub.status.busy": "2025-02-27T15:25:24.247027Z",
     "iopub.status.idle": "2025-02-27T15:25:28.464502Z",
     "shell.execute_reply": "2025-02-27T15:25:28.463792Z",
     "shell.execute_reply.started": "2025-02-27T15:25:24.247310Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import gc\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:25:28.465840Z",
     "iopub.status.busy": "2025-02-27T15:25:28.465440Z",
     "iopub.status.idle": "2025-02-27T15:25:28.714713Z",
     "shell.execute_reply": "2025-02-27T15:25:28.713847Z",
     "shell.execute_reply.started": "2025-02-27T15:25:28.465816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Using GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "print(\"Using GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:25:31.951501Z",
     "iopub.status.busy": "2025-02-27T15:25:31.951221Z",
     "iopub.status.idle": "2025-02-27T15:25:32.596357Z",
     "shell.execute_reply": "2025-02-27T15:25:32.595224Z",
     "shell.execute_reply.started": "2025-02-27T15:25:31.951481Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('/kaggle/input/marked-data/marked_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:25:34.474191Z",
     "iopub.status.busy": "2025-02-27T15:25:34.473597Z",
     "iopub.status.idle": "2025-02-27T15:25:43.681022Z",
     "shell.execute_reply": "2025-02-27T15:25:43.680268Z",
     "shell.execute_reply.started": "2025-02-27T15:25:34.474162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0878f241f3f4d34a6900d4413f5285e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"/kaggle/input/deepseek-r1/transformers/deepseek-r1-distill-qwen-7b/2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:25:45.833263Z",
     "iopub.status.busy": "2025-02-27T15:25:45.832502Z",
     "iopub.status.idle": "2025-02-27T15:25:45.838950Z",
     "shell.execute_reply": "2025-02-27T15:25:45.838082Z",
     "shell.execute_reply.started": "2025-02-27T15:25:45.833233Z"
    }
   },
   "outputs": [],
   "source": [
    "def request_to_model(comment, prompt):\n",
    "    prompt = f\"'{prompt}''{comment}'\"\n",
    "    messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=100000,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:25:49.372824Z",
     "iopub.status.busy": "2025-02-27T15:25:49.372466Z",
     "iopub.status.idle": "2025-02-27T15:25:49.376830Z",
     "shell.execute_reply": "2025-02-27T15:25:49.375849Z",
     "shell.execute_reply.started": "2025-02-27T15:25:49.372795Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt1 = (\n",
    "            f\"What is the sentiment expressed in the following comment?\"\n",
    "            f\"Select sentiment value from positive, negative, or neutral. \"\n",
    "            f\"Return only the sentiment value in small letters.\\n\\n\"\n",
    "            f\"comment: \"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:25:55.356855Z",
     "iopub.status.busy": "2025-02-27T15:25:55.356518Z",
     "iopub.status.idle": "2025-02-27T16:28:05.788117Z",
     "shell.execute_reply": "2025-02-27T16:28:05.787163Z",
     "shell.execute_reply.started": "2025-02-27T15:25:55.356825Z"
    }
   },
   "outputs": [],
   "source": [
    "result_responses = list()\n",
    "time_res = list()\n",
    "i_comment = list()\n",
    "answer = list()\n",
    "sentiment = list()\n",
    "for i in range(8000,8100):\n",
    "    start_time = time.time()  \n",
    "    comment = data['text'][i]\n",
    "    res = request_to_model(comment, prompt1)\n",
    "    result_responses.append(res) \n",
    "    stop_time = time.time()\n",
    "    time_res.append(stop_time - start_time)\n",
    "    i_comment.append(i)\n",
    "    if \"</think>\" in res:\n",
    "        sentiment.append(res.split(\"</think>\\n\\n\",1)[1])\n",
    "    else:\n",
    "        sentiment.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:28:23.022386Z",
     "iopub.status.busy": "2025-02-27T16:28:23.022037Z",
     "iopub.status.idle": "2025-02-27T16:28:23.027826Z",
     "shell.execute_reply": "2025-02-27T16:28:23.026947Z",
     "shell.execute_reply.started": "2025-02-27T16:28:23.022356Z"
    }
   },
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'i_comment': i_comment,'text_response': result_responses, 'time': time_res, 'sentiment': sentiment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:28:35.019757Z",
     "iopub.status.busy": "2025-02-27T16:28:35.019455Z",
     "iopub.status.idle": "2025-02-27T16:28:35.034642Z",
     "shell.execute_reply": "2025-02-27T16:28:35.033546Z",
     "shell.execute_reply.started": "2025-02-27T16:28:35.019734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_comment</th>\n",
       "      <th>text_response</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>Okay, so I need to figure out the sentiment of...</td>\n",
       "      <td>35.726094</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>Okay, I need to determine the sentiment of the...</td>\n",
       "      <td>26.031150</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>Okay, so I need to determine the sentiment of ...</td>\n",
       "      <td>26.204930</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>Okay, so I need to figure out the sentiment of...</td>\n",
       "      <td>38.960386</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>Okay, so I'm trying to figure out the sentimen...</td>\n",
       "      <td>35.791315</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8095</td>\n",
       "      <td>Okay, so I need to figure out the sentiment of...</td>\n",
       "      <td>39.299850</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8096</td>\n",
       "      <td>Okay, I need to determine the sentiment of the...</td>\n",
       "      <td>30.897975</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>8097</td>\n",
       "      <td>Alright, so I need to figure out the sentiment...</td>\n",
       "      <td>37.158324</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8098</td>\n",
       "      <td>Alright, I need to figure out the sentiment of...</td>\n",
       "      <td>34.660710</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8099</td>\n",
       "      <td>Okay, I need to determine the sentiment of the...</td>\n",
       "      <td>35.481070</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    i_comment                                      text_response       time  \\\n",
       "0        8000  Okay, so I need to figure out the sentiment of...  35.726094   \n",
       "1        8001  Okay, I need to determine the sentiment of the...  26.031150   \n",
       "2        8002  Okay, so I need to determine the sentiment of ...  26.204930   \n",
       "3        8003  Okay, so I need to figure out the sentiment of...  38.960386   \n",
       "4        8004  Okay, so I'm trying to figure out the sentimen...  35.791315   \n",
       "..        ...                                                ...        ...   \n",
       "95       8095  Okay, so I need to figure out the sentiment of...  39.299850   \n",
       "96       8096  Okay, I need to determine the sentiment of the...  30.897975   \n",
       "97       8097  Alright, so I need to figure out the sentiment...  37.158324   \n",
       "98       8098  Alright, I need to figure out the sentiment of...  34.660710   \n",
       "99       8099  Okay, I need to determine the sentiment of the...  35.481070   \n",
       "\n",
       "   sentiment  \n",
       "0   negative  \n",
       "1   positive  \n",
       "2   negative  \n",
       "3   negative  \n",
       "4   positive  \n",
       "..       ...  \n",
       "95  negative  \n",
       "96  positive  \n",
       "97  negative  \n",
       "98   neutral  \n",
       "99  negative  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:35:09.196755Z",
     "iopub.status.busy": "2025-02-27T16:35:09.196418Z",
     "iopub.status.idle": "2025-02-27T16:35:09.236846Z",
     "shell.execute_reply": "2025-02-27T16:35:09.236022Z",
     "shell.execute_reply.started": "2025-02-27T16:35:09.196727Z"
    }
   },
   "outputs": [],
   "source": [
    "df_res.to_excel('df_DeepSeek_8000-8099.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6753975,
     "sourceId": 10871062,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 225262,
     "modelInstanceId": 204046,
     "sourceId": 256586,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
